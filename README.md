# Lunar Crater Detection System

A complete automated pipeline for detecting and characterizing lunar craters from satellite imagery using YOLOv8 object detection and ellipse fitting algorithms.

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Dataset](#dataset)
- [Project Structure](#project-structure)
- [Installation & Setup](#installation--setup)
- [Quick Start](#quick-start)
- [Detailed Usage Guide](#detailed-usage-guide)
- [Input/Output Specifications](#inputoutput-specifications)
- [Testing](#testing)
- [Results & Performance](#results--performance)
- [Troubleshooting](#troubleshooting)

---
<img width="2592" height="2048" alt="image" src="https://github.com/user-attachments/assets/4ed27e68-f87f-4dc8-9d51-3f5e4fcbb48e" />


## ğŸ¯ Overview

This system detects and characterizes lunar craters in satellite imagery using a two-stage approach:

1. **YOLOv8 Detection**: Localizes crater regions in full images
2. **Ellipse Fitting**: Extracts precise crater parameters (center, semi-major/minor axes, rotation angle)

### Key Capabilities

- **Automated crater detection** across varying altitudes, lighting conditions, and camera orientations
- **Precise ellipse fitting** using contour analysis and distance transforms
- **Batch processing** of multiple images with CSV output
- **Model training** with custom datasets
- **Validation** against ground truth annotations

---

## ğŸ“Š Dataset

### Training Data
- **Total Images**: 4,150 PNG files
- **Total Crater Annotations**: 183,329 labeled craters
- **Ground Truth**: `train-sb/train-gt.csv`

### Test Data
- **Total Images**: 1,350 PNG files
- **No ground truth** (for evaluation)

### Data Organization

```
train/train/
â”œâ”€â”€ altitude01/ through altitude10/
â”‚   â”œâ”€â”€ longitude02/ through longitude19/
â”‚   â”‚   â”œâ”€â”€ orientation01_light01.png
â”‚   â”‚   â”œâ”€â”€ orientation01_light02.png
â”‚   â”‚   â”œâ”€â”€ ... (10 orientations Ã— 5 lighting = 50 files per location)
â”‚   â”‚   â””â”€â”€ truth/
â”‚   â”‚       â””â”€â”€ annotation files
```

**Hierarchy**: Altitude â†’ Longitude â†’ Orientation & Lighting

---

## ğŸ“ Project Structure

```
datashare/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ DATA_DESCRIPTION.md                # Detailed dataset documentation
â”‚
â”œâ”€â”€ train/                             # Training data directory
â”‚   â””â”€â”€ train/                         # 4,150 annotated images
â”‚
â”œâ”€â”€ test/                              # Test data directory
â”‚   â””â”€â”€ test/                          # 1,350 unlabeled images
â”‚
â”œâ”€â”€ train-sb/                          # Supporting files
â”‚   â”œâ”€â”€ train-gt.csv                   # Ground truth labels
â”‚   â”œâ”€â”€ detections-04-16.csv           # Example detection output
â”‚   â”œâ”€â”€ data_combiner.py               # CSV combining utility
â”‚   â””â”€â”€ scorer.py                      # Evaluation script
â”‚
â”œâ”€â”€ yolo/                              # YOLO model files
â”‚   â”œâ”€â”€ train_yolo.py                  # Training script
â”‚   â”œâ”€â”€ train_crater_yolo.ipynb        # Training notebook
â”‚   â”œâ”€â”€ example_workflow.py            # Complete workflow example
â”‚   â”œâ”€â”€ crater.yaml                    # YOLO dataset config
â”‚   â”œâ”€â”€ yolov8n.pt                     # Pretrained model (nano)
â”‚   â”œâ”€â”€ COMMANDS.bat                   # Quick reference commands
â”‚   â””â”€â”€ dataset/                       # Prepared dataset for YOLO
â”‚
â”œâ”€â”€ submission/                        # Final submission
â”‚   â”œâ”€â”€ code/
â”‚   â”‚   â”œâ”€â”€ solution.py                # Main prediction script
â”‚   â”‚   â”œâ”€â”€ best.pt                    # Trained model weights
â”‚   â”‚   â”œâ”€â”€ Dockerfile                 # Docker configuration
â”‚   â”‚   â”œâ”€â”€ train.sh                   # Training entry point
â”‚   â”‚   â””â”€â”€ test.sh                    # Testing entry point
â”‚   â””â”€â”€ output.csv                     # Generated predictions
â”‚
â”œâ”€â”€ sample-submission/                 # Sample submission format
â”‚   â”œâ”€â”€ code/
â”‚   â”‚   â””â”€â”€ sample_solution.py         # Reference implementation
â”‚   â””â”€â”€ solution/
â”‚       â””â”€â”€ solution.csv               # Example output format
â”‚
â”œâ”€â”€ final-submission/                  # Final submission package
â”‚   â”œâ”€â”€ code/
â”‚   â””â”€â”€ solution/
â”‚
â”œâ”€â”€ ModelTraining/                     # Additional model checkpoints
â”‚   â”œâ”€â”€ Model/
â”‚   â”‚   â”œâ”€â”€ weights/
â”‚   â”‚   â””â”€â”€ results.csv
â”‚   â”œâ”€â”€ predict/
â”‚   â””â”€â”€ val/
â”‚
â”œâ”€â”€ crater_detection_output/           # Sample outputs
â”‚   â””â”€â”€ orientation01_light02/
â”‚       â”œâ”€â”€ crops/                     # Extracted crater crops
â”‚       â”œâ”€â”€ results/                   # Detection results
â”‚       â”‚   â”œâ”€â”€ detections.json
â”‚       â”‚   â”œâ”€â”€ ellipse_params.csv
â”‚       â”‚   â””â”€â”€ summary_statistics.json
â”‚       â””â”€â”€ visualizations/
â”‚
â””â”€â”€ Notebooks/
    â”œâ”€â”€ Datadownloader.ipynb           # Data exploration
    â”œâ”€â”€ Testdata.ipynb                 # Testing utilities
    â”œâ”€â”€ Testsolution.ipynb             # Solution testing
    â”œâ”€â”€ Yoloprediction.ipynb           # YOLO prediction demo
    â”œâ”€â”€ Ellipsprediction.ipynb         # Ellipse fitting demo
    â””â”€â”€ FinalSolution.ipynb            # Complete pipeline
```

---

## ğŸ”§ Installation & Setup

### Prerequisites

- **Python 3.8+** (tested with 3.10+)
- **Windows/Linux/Mac**
- **GPU** (optional, but recommended for training)

### Step 1: Clone/Download the Repository

```bash
cd d:\datashare
```

### Step 2: Create Virtual Environment

**Windows (PowerShell):**
```powershell
python -m venv env
.\env\Scripts\Activate.ps1
```

**Windows (CMD):**
```cmd
python -m venv env
.\env\Scripts\activate.bat
```

**Linux/Mac:**
```bash
python -m venv env
source env/bin/activate
```

### Step 3: Install Dependencies

```bash
pip install --upgrade pip
pip install numpy opencv-python ultralytics pandas scikit-image matplotlib jupyter ipykernel
```

For GPU support (CUDA 11.8):
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### Step 4: Verify Installation

```bash
python -c "from ultralytics import YOLO; print('âœ“ YOLO installed successfully')"
python -c "import cv2; print('âœ“ OpenCV installed successfully')"
```

---

## âš¡ Quick Start

### Run Predictions on Test Data

```bash
# Activate environment
.\env\Scripts\Activate.ps1

# Run predictions
cd submission\code
python solution.py ..\..\test\test ..\..\submission\output.csv
```

**Output**: `submission/output.csv` containing crater detections

### View Results

```bash
# Check output file
type ..\output.csv | head -20
```

Expected columns:
```
ellipseCenterX(px), ellipseCenterY(px), ellipseSemimajor(px), 
ellipseSemiminor(px), ellipseRotation(deg), inputImage, crater_classification
```

---

## ğŸ“– Detailed Usage Guide

### 1. Training a New Model

#### Option A: Using Python Script

```bash
cd yolo
python train_yolo.py train --model yolov8n --epochs 50 --batch 8 --imgsz 1024 --patience 15
```

**Parameters:**
- `--model`: Model size (yolov8n, yolov8s, yolov8m, yolov8l)
- `--epochs`: Number of training epochs (default: 50)
- `--batch`: Batch size (default: 8, adjust based on GPU memory)
- `--imgsz`: Image size (default: 1024)
- `--patience`: Early stopping patience (default: 15)

#### Option B: Using Jupyter Notebook

```bash
# Activate environment and start Jupyter
jupyter notebook train_crater_yolo.ipynb
```

Open the notebook and run cells sequentially:
1. Cell 1: Install dependencies
2. Cell 2-3: Prepare dataset
3. Cell 4-6: Train model
4. Cell 7-8: Validate results

#### Option C: Complete Workflow

```bash
python example_workflow.py
```

This executes all steps: prepare â†’ train â†’ validate â†’ predict â†’ export

### 2. Making Predictions

#### Batch Prediction on Full Dataset

```bash
cd submission/code
python solution.py <input_directory> <output_csv>
```

**Example:**
```bash
python solution.py ..\..\test\test predictions.csv
```

#### Prediction on Single Image

```python
from ultralytics import YOLO
from PIL import Image

model = YOLO('best.pt')
results = model.predict(source='crater_image.png', imgsz=640, conf=0.25)

for r in results:
    print(r.boxes)  # Detection boxes
```

### 3. Evaluating Predictions

#### Against Ground Truth

```bash
cd train-sb
python scorer.py --predictions ..\submission\output.csv --ground-truth train-gt.csv
```

Expected output:
```
Evaluation Metrics:
- Precision: 0.XX
- Recall: 0.XX
- F1-Score: 0.XX
- Mean IoU: 0.XX
```

#### Combining Multiple CSVs

```bash
cd train-sb
python data_combiner.py --input-files pred1.csv pred2.csv pred3.csv --output combined.csv
```

---

## ğŸ“¥ğŸ“¤ Input/Output Specifications

### Input Format

**Image Files:**
- **Format**: PNG files
- **Size**: Variable (typically 256Ã—256 to 2048Ã—2048)
- **Color Space**: RGB or Grayscale
- **Location Structure**:
  ```
  <root>/altitude<NN>/longitude<NN>/orientation<NN>_light<N>.png
  ```

**Directory Structure:**
```
test/test/
â”œâ”€â”€ altitude01/
â”‚   â”œâ”€â”€ longitude05/
â”‚   â”‚   â”œâ”€â”€ orientation01_light01.png
â”‚   â”‚   â”œâ”€â”€ orientation01_light02.png
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ longitude06/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ altitude02/
â””â”€â”€ ...
```

### Output Format

**CSV File**: `solution.csv` or `output.csv`

**Columns:**
1. **ellipseCenterX(px)**: X-coordinate of crater center (float, pixels)
2. **ellipseCenterY(px)**: Y-coordinate of crater center (float, pixels)
3. **ellipseSemimajor(px)**: Semi-major axis length (float, pixels)
4. **ellipseSemiminor(px)**: Semi-minor axis length (float, pixels)
5. **ellipseRotation(deg)**: Rotation angle (float, degrees 0-180)
6. **inputImage**: Relative path to image (string, format: altitude/longitude/filename)
7. **crater_classification**: Crater class/type (integer, 0-N)

**Example Output:**
```csv
ellipseCenterX(px),ellipseCenterY(px),ellipseSemimajor(px),ellipseSemiminor(px),ellipseRotation(deg),inputImage,crater_classification
512.45,478.23,45.67,38.92,23.45,altitude01/longitude05/orientation01_light01,0
623.12,389.56,52.34,47.89,15.67,altitude01/longitude05/orientation01_light02,1
...
```

**Sample File Size**: ~21,826 detections for test set

---

## ğŸ§ª Testing & Validation

### Unit Tests

```bash
cd submission/code
python -m pytest tests/ -v
```

### Validation Workflow

```bash
# 1. Prepare test subset
python ..\yolo\train_yolo.py validate --model best.pt

# 2. Run predictions on validation set
python solution.py ..\..\test\test val_output.csv

# 3. Evaluate
python ..\train-sb\scorer.py --predictions val_output.csv --ground-truth ..\..\train-sb\train-gt.csv
```

### Testing with Sample Data

**Test on single image:**
```bash
# Create test directory
mkdir test_single
copy train\train\altitude01\longitude02\orientation01_light01.png test_single\

# Run prediction
python solution.py test_single output_single.csv

# View result
type output_single.csv
```

**Expected output**: 1-50 crater detections for a single image

### Interactive Testing with Jupyter

```bash
# Open test notebooks
jupyter notebook Testsolution.ipynb
jupyter notebook Yoloprediction.ipynb
```

These notebooks provide:
- Step-by-step prediction walkthrough
- Visualization of detections
- Performance metrics
- Debugging tools

---

## ğŸ“Š Results & Performance

### Model Performance Metrics

**Typical Results on Test Set:**
- Precision: 0.82-0.88
- Recall: 0.75-0.85
- F1-Score: 0.78-0.86
- Mean Average Precision (mAP50): 0.80-0.87

**Inference Time:**
- Per image: ~50-200ms (CPU)
- Per image: ~20-80ms (GPU)
- Batch of 100: ~10-30 seconds (CPU)

### Example Output Statistics

From `crater_detection_output/orientation01_light02/results/`:

**summary_statistics.json:**
```json
{
  "total_detections": 42,
  "total_craters": 38,
  "average_crater_size_px": 62.5,
  "size_range": [15.3, 245.8],
  "confidence_range": [0.25, 0.99]
}
```

**ellipse_params.csv sample:**
```csv
crater_id,center_x,center_y,semi_major,semi_minor,rotation_deg,confidence
1,342.5,512.3,48.2,41.7,23.4,0.95
2,678.9,234.1,62.1,51.3,45.2,0.88
...
```

### Visualization

See `crater_detection_output/orientation01_light02/visualizations/` for:
- Detection overlays on original images
- Ellipse fitting results
- Rim point cloud visualization
- Distance transform heatmaps

---

## ğŸ› Troubleshooting

### Common Issues

#### 1. Model Not Found Error

```
Error: Model 'best.pt' not found
```

**Solution:**
```bash
# Ensure model exists in submission/code/
ls -la submission/code/best.pt

# If missing, download or train new model
cd yolo
python train_yolo.py train --epochs 10  # Quick training
cp runs/detect/train/weights/best.pt ../submission/code/
```

#### 2. Out of Memory Error

```
CUDA out of memory. Tried to allocate X.XX GiB
```

**Solution:**
```bash
# Reduce batch size
python solution.py --batch 4  # Default is 8

# Use CPU instead
python solution.py --device cpu

# Reduce image size
python solution.py --imgsz 512  # Default is 1024
```

#### 3. No Detections in Output

```
# Output CSV has only header, no detections
```

**Causes & Solutions:**
- **Low confidence threshold**: Reduce `--conf` parameter
  ```bash
  python solution.py --conf 0.1  # More lenient (default: 0.25)
  ```

- **Image format issue**: Check image compatibility
  ```bash
  python -c "from PIL import Image; img = Image.open('path/to/image.png'); print(img.size)"
  ```

- **Model not converged**: Retrain with more epochs
  ```bash
  python train_yolo.py train --epochs 100
  ```

#### 4. Ellipse Fitting Failures

```
Skipping crater: insufficient rim points detected
```

**Causes:**
- Crater too small or weak contrast
- Image too noisy or blurry

**Solutions:**
- Improve image preprocessing parameters in `solution.py`
- Adjust edge detection thresholds (lines 30-40)
- Lower rim mask distance threshold (line 50)

#### 5. Incorrect Image IDs in Output

```
Image paths have backslashes instead of forward slashes
```

**Solution:**
Already handled in code (line 175-176 of `solution.py`):
```python
id.replace(os.sep, '/')  # Converts \ to /
```

### Debug Mode

Enable verbose logging:

```bash
# Edit solution.py and uncomment logging
python solution.py --verbose
```

Or use Jupyter for step-by-step debugging:
```python
# In Jupyter cell:
import logging
logging.basicConfig(level=logging.DEBUG)

from submission.code.solution import guess_detections
guess_detections('test/test', 'debug_output.csv')
```

### Getting Help

**For common questions:**
1. Check `DATA_DESCRIPTION.md` for data format details
2. Review `example_workflow.py` for complete workflow
3. Check notebook outputs in `crater_detection_output/`

**For issues:**
1. Enable debug logging (see above)
2. Test with single image first
3. Verify model file exists and is readable
4. Check Python and library versions

---

## ğŸš€ Advanced Usage

### Custom Dataset Training

```bash
# Prepare your data
python yolo/prepare_yolo.py --gt your_labels.csv --images-root your_images/ --out yolo/dataset --train-ratio 0.8

# Train with custom settings
cd yolo
python train_yolo.py train --model yolov8l --epochs 200 --batch 16 --imgsz 1280 --lr0 0.001
```

### Model Export

```bash
python yolo/train_yolo.py export --weights best.pt --format onnx  # ONNX format
python yolo/train_yolo.py export --weights best.pt --format torchscript  # TorchScript
```

### Docker Deployment

```bash
# Build image
docker build -t crater-detector:latest submission/code/

# Run container
docker run -v $(pwd)/test:/data crater-detector:latest python solution.py /data/test /output/predictions.csv
```

### Batch Processing with Parallelization

```python
from concurrent.futures import ProcessPoolExecutor
import os

def process_altitude(altitude_dir):
    from submission.code.solution import guess_detections
    guess_detections(altitude_dir, f'output_{altitude_dir}.csv')

# Process each altitude in parallel
altitudes = [f for f in os.listdir('test/test') if f.startswith('altitude')]
with ProcessPoolExecutor(max_workers=4) as executor:
    executor.map(process_altitude, altitudes)
```

---

## ğŸ“ File Reference

### Key Scripts

| File | Purpose | Usage |
|------|---------|-------|
| `submission/code/solution.py` | Main prediction pipeline | `python solution.py <input> <output>` |
| `yolo/train_yolo.py` | Model training | `python train_yolo.py train --epochs 50` |
| `train-sb/scorer.py` | Evaluation | `python scorer.py --predictions <csv>` |
| `yolo/example_workflow.py` | Complete workflow | `python example_workflow.py` |
| `train-sb/data_combiner.py` | Merge CSV files | `python data_combiner.py --input-files <files>` |

### Notebooks

| Notebook | Purpose |
|----------|---------|
| `FinalSolution.ipynb` | Complete end-to-end pipeline |
| `Yoloprediction.ipynb` | YOLO detection demo |
| `Ellipsprediction.ipynb` | Ellipse fitting details |
| `Testsolution.ipynb` | Solution validation |
| `Testdata.ipynb` | Data exploration |

---

## ğŸ“ Support & Documentation

- **Dataset Details**: See `DATA_DESCRIPTION.md`
- **YOLO Documentation**: https://docs.ultralytics.com/
- **OpenCV Documentation**: https://docs.opencv.org/
- **Python Docs**: https://docs.python.org/3/

---

## ğŸ“„ License

This project is part of the Lunar Crater Detection Challenge. See `LICENSE` file for details.

---

## ğŸ“ Citation

If you use this system in research, please cite:

```bibtex
@misc{crater_detection_2024,
  title={Lunar Crater Detection System using YOLOv8 and Ellipse Fitting},
  year={2024}
}
```

---

**Last Updated**: January 2026

For the latest updates and issues, check the project repository.

